+slide
section#ID_Tell_Me_Where_to_Look_Guided_Attention_Inference_Network
  .paper-abstract
    .title Tell Me Where to Look : Guided Attention Inference Network
    .info
      .authors Kunpeng Li, Ziyan Wu, Kuan-Chuan Peng, Jan Ernst, Yun Fu
      .conference CVPR2018, arXive: 1802.10171
      .paper_id 1247
    .slide_editor Hiroshi Fukui
  
    .item1
      .text
        h1 概要
        p 弱教師あり学習で得られる物体のローカライゼーションを高精度にする研究．
          |方法としては2つ提案しており，
        ol
          li GAPのローカライゼーションを用いて物体の領域と背景の領域を明示的に学習させる方法と，
          li セマンティックセグメンテーションのラベルを用いて物体の詳細な領域を学習させる方法がある．
            |セマンティックセグメンテーションと視覚的解釈に対する評価をしており，どちらのタスクも高い性能を示している．
    .item2
      .text
        p
          img(src=`${figpath}1247_overview.png`,alt="1247_overview.png")
    .item3
      .text
        h1 新規性・結果・なぜ通ったか？
        p 1)の方法では，2streamなCNNをベースにしており，入力はそれぞれ通常の画像と，GAPのローカライゼーションから物体領域を排除した画像を入力する．
          |この処理により，物体と背景を明示的に学習できる．
          |そして，セマンティックセグメンテーションでは，
          |1)のネットワークに加えて，セマンティックセグメンテーションのラベルと出力したAttention mapとの誤差を算出させることで，Attention mapを最適化させる．
          |Pascal VOCのweakly-supervisedによるセマンティックセグメンテーションのタスクで評価し，高い性能を示している．
          |また，発生するAttention mapの領域に対してオリジナルのデータセットを作成して評価している．
    .item4
      .text
        h1 コメント・リンク集
        ul
          li
            a(href="https://arxiv.org/abs/1802.10171") 論文リンク
    .slide_index #{getSlideIndex()}
    .timestamp 2018.5.2 13:37:25


