+slide
section#ID_Boosting_Adversarial_Attacks_with_Momentum
  .paper-abstract
    .title Boosting Adversarial Attacks with Momentum
    .info
      .authors Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li
      .conference CVPR2018
    .slide_editor Kazuma Matsui

    .item1
      .text
        h1 概要
        p DNNsは，アルゴリズムに対するセキュリティ上の懸念をもたらす，敵対的な攻撃に対して脆弱である．敵対的攻撃は，ディープ・ラーニング・モデルが展開される前の頑健性を評価する重要な代理として機能する．しかし，既存の攻撃の大半は精度の低いブラックボックスモデルしかだますことができない．この問題に対処するため，反撃攻撃を促進するために，運動量ベースの反復アルゴリズムの幅広いクラスを提案する．攻撃の成功率を向上させるために，モンテウム反復アルゴリズムをアンサンブルモデルに適用し，強力な防御能力を備えた対抗的に訓練されたモデルも攻撃に対して脆弱であることを示す．提案された方法は，様々な深いモデルや防衛方法の頑健性を評価するためのベンチマークとして役立つと考えられる．
    .item2
      .text
        p
          img(src=`${figpath}Boosting_Adversarial_Attacks_with_Momentum_.png`,alt="Boosting_Adversarial_Attacks_with_Momentum_.png")
    .item3
      .text
        h1 新規性・結果・なぜ通ったか？
        p Ensembleの敵対的訓練は、訓練されたモデルだけでなく、他の拘束モデルからも生成された敵対的なサンプルを用いて訓練データを補強する．したがって、アンサンブルの訓練を受けたモデルは、ワンステップ攻撃とブラックボックス攻撃に対して堅牢である.本稿では，ブラックボックスモデルだけでなくホワイトボックスモデルを効果的に欺くことができる反撃攻撃を促進するための，広範なモーダルベース反復手法を提案する．この手法は，一段階のグラジエントベースの方法とバニラの反復法を一貫してブラックボックス方式より優れている．本研究では提案された方法の有効性を検証し，それらが実際に働く理由を説明するために広範な実験を行う．生成された敵対的な例の転送可能性をさらに向上させるため，ログが融合されたモデルのアンサンブルを攻撃することを提案する．アンサンブル敵対的訓練によって得られたモデルはブラックボックス攻撃に対して脆弱であり，より堅牢な深い学習モデルの開発のための新たなセキュリティ問題を引き起こすことを示している．
    .item4
      .text
        h1 コメント・リンク集
        ul
          li
            a(href="https://arxiv.org/abs/1710.06081") 論文
    .slide_index #{getSlideIndex()}
    .timestamp 2018.8.2 14:12:22
