+slide
section#ID_Excitation_Backprop_for_RNNs
  .paper-abstract
    .title Excitation Backprop for RNNs
    .info
      .authors Sarah Adel Bargal, et al.,
      .conference CVPR 2018
    .slide_editor Munetaka Minoguchi
  
    .item1
      h1 概要
      .text.
        動画におけるクラス推定やキャプショニングにおいて、RNNが使用されたという証拠を空間的に立証するExcitation Backprop(EB)の提案。入力動画に対して、どの部分がクラス分類/キャプショニングの根拠になったのか、顕著性マップを出力して可視化。トップダウンの顕著性によって、単一パスで空間的および時間的な証拠を同時に立証するように定式化。

    .item2
      img(src=figpath+"180730EBfR.jpg")

    .item3
      h1 新規性・結果・なぜ通ったか？
      .text
        p RNNが何を根拠にタスクをこなすのか、GradCamのように出力するモデルの提案。図は、CliffDivingとHorseRidingの両方を含む動画において、アクティブクラスであるCliffDivingの顕著性を強調している例。

    .item4
      h1 コメント・リンク集
      .text
        p ActionとCaptionにて実験。単語に対するローカライズの精度は良い印象だが、キャプショニングの場合の精度は微妙。
        ul
          li: a(href="https://arxiv.org/pdf/1711.06778.pdf") 論文
    .slide_index #{getSlideIndex()}
    .timestamp 2018.7.30 21:42:53


