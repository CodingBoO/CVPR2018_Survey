+slide
section#ID_Flow_Guided_Recurrent_Neural_Encoder_for_Video_Salient_Object_Detection
  .paper-abstract
    .title Flow Guided Recurrent Neural Encoder for Video Salient Object Detection
    .info
      .authors Guanbin Li, Yuan Xie, Tianhao Wei, Keze Wang and Liang Lin
      .conference CVPR2018
      .paper_id 403
    .slide_editor: a(href="http://www.mprg.cs.chubu.ac.jp/~ryorsk/") Ryosuke Araki

    .item1
      .text
        h1 概要
        p 動画のsalient object detection（SOD）をend-to-endで学習するflow guided recurrent neural encoder（FGRNE）を提案．Optical flowとsequential feature evolution encodingの情報をLSTMで用いることで，フレームごとの特徴量の時間的コヒーレンスを強化する．これは，FCNベースのstatic saliency detectorを動画のSODに拡張する普遍的なフレームワークであると言える．
    .item2
      .text
        p
          img(src=`${figpath}20180723_FGRNE.jpg`,alt="20180723_FGRNE.jpg")
    .item3
      .text
        h1 新規性・結果・なぜ通ったか？
        p SOTAのsaliency detectorを画像から動画に拡張した．DAVISとFBMSデータセットを用いて比較した結果，様々な手法と比較して最も良い性能を達成した．
    .item4
      .text
        h1 コメント・リンク集
        p Saliency mapを比較すると，他の手法はうまく検出できないか細部が欠けているが，提案手法はGTに近い．
        ul
          li
            a(href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1226.pdf") 論文
    .slide_index #{getSlideIndex()}
    .timestamp 2018.7.23 16:09:36
