+slide
section#Efficient_Video_Object_Segmentation_via_Network_Modulation
  .paper-abstract
    .title Efficient Video Object Segmentation via Network Modulation
    .info
      .authors Linjie Yang, Yanran Wang, Xuehan Xiong, Jianchao Yang, Aggelos K. Katsaggelos
      .conference CVPR 2018
    .slide_editor: a(href="http://hirokatsukataoka.net/" target="blank") Hirokatsu Kataoka

    .item1
      .text
        h1 概要
        p セグメンテーションを実行する際に任意のアノテーション済み物体を事前情報（Spatial Prior）として高精度化を図るための技術を提供する。本論文では、最初の一フレームに対してセグメンテーションを行うだけで、動画中の物体に対してセグメンテーションを行うモデルを提案する。アノテーションから抽出した事前情報はニューラルネットの中間層にて情報を挿入して抽象化を行う。図は提案のフレームワークを示しており、VisualModulator（初期フレームのアノテーションから視覚的なガイドを行う）、SegmentationNet（VisualModulator/SpatialModulatorの補助を受けつつ、RGB画像の入力からセグメンテーションを実行）、SpatialModulator（空間的にどこらへんに対象物体があるかをサポート）の３つのコンポーネントから構成される。
    .item2
      .text
        p
          img(src=`${figpath}180604NetworkModulation.png`,alt="180604NetworkModulation")
    .item3
      .text
        h1 新規性・結果・なぜ通ったか？
        p 最初のフレームのアノテーションのみから動画セグメンテーションを実行するという問題を提供した、さらに視覚的な特徴量/位置的な事前知識をセグメンテーションのネットワークに導入し、動画セグメンテーションを高精度化した点が評価された。動画セグメンテーションタスクであるDAVIS2016にて74.0、YoutubeOjbsにて69.0（処理速度は0.14second/image）であった。State-of-the-artには劣る（それぞれ79.8, 74.1）が、処理速度では優っている（提案 0.14 vs. 従来 10.0）。
    .item4
      .text
        h1 コメント・リンク集
        p メタ学習の枠組みを使用している。
        ul
          li
            a(href="https://arxiv.org/abs/1802.01218") 論文
          li
            a(href="https://github.com/linjieyangsc/video_seg") GitHub
    .slide_index #{getSlideIndex()}
    .timestamp 2018.6.4 20:56:17
