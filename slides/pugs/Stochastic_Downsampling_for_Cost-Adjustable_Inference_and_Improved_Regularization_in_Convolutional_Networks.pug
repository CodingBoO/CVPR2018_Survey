+slide
section#ID_Stochastic_Downsampling_for_Cost-Adjustable_Inference_and_Improved_Regularization_in_Convolutional_Networks
  .paper-abstract
    .title Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks
    .info
      .authors Jason Kuen, Xiangfei Kong, Zhe Lin, Gang Wang, Jianxiong Yin, Simon See and Yap-Peng Tan
      .conference CVPR2018
      .paper_id 1801.09335
    .slide_editor Kenichiro Wani

    .item1
      .text
        h1 概要
        p 推論の間により効率的に動作するように畳み込みネットワーク（CNN）を訓練することが望ましい。しかし，多くの場合，推論のためにシステムが持っている計算予算は，トレーニング中に事前に知ることができないか，または推論予算は，変化するリアルタイムリソースの利用可能性に依存する。したがって，推論コストが調整できず，様々な推論予算に適応できない，単なる推論効率の良いCNNを訓練することは不十分である。確率的ダウンサンプリング点（SDPoint）であるCNNにおけるコスト調整可能な推論のための新しいアプローチを提案する。
    .item2
      .text
        p
          img(src=`${figpath}Stochastic_Downsampling_for_Cost-Adjustable_Inference_and_Improved_Regularization_in_Convolutional_Networks.png`,alt="Item3Image")
    .item3
      .text
        h1 新規性・結果・なぜ通ったか？
        p 余分なパラメータとトレーニングコストがかからないため，SDPointは効果的なコスト調整可能な推測を容易にし，ネットワークの正則化（したがって正確なパフォーマンス）を大幅に改善する。
    .item4
      .text
        h1 コメント・リンク集
        ol
          li
            a(href="https://arxiv.org/abs/1801.09335") link
    .slide_index #{getSlideIndex()}
    .timestamp 2018.8.3 14:46:13
