+slide
section#ID_Explicit_Loss-Error-Aware_Quantization_for_Low-Bit_Deep_Neural_Networks
  .paper-abstract
    .title Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks
    .info
      .authors Aojun Zhou, Intel labs china; Anbang Yao
      .conference CVPR 2018
    .slide_editor Kazushige Okayasu

    .item1
      .text
        h1 概要
        p 3値や2値などの非常に低ビットのパラメータ値を持つDNNモデルを顕著な損失なく32ビットの浮動小数点数に近似させる新しい方法であるELLS(Explicit Loss-Error-Aware Quantization)を提案
    .item2
      .text
        p
          img(src=`${figpath}Explicit_Loss-Error-Aware_Quantization_for_Low-Bit_Deep_Neural_Networks.pug`,alt="Explicit_Loss-Error-Aware_Quantization_for_Low-Bit_Deep_Neural_Networks")
    .item3
      .text
        h1 新規性・結果・なぜ通ったか？
        p Imagenetでの実験では量子化を行ったことによる精度の低下の少なさでstate-of-the-art
    .item4
      .text
        h1 コメント・リンク集
        ul
          li
            a(href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.pdf") 論文
    .slide_index #{getSlideIndex()}
    .timestamp 2018.7.30 18:10:58
